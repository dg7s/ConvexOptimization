{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f786a078",
   "metadata": {},
   "source": [
    "# Learning a quadratic pseudo-metric from distance measurements\n",
    "\n",
    "Recall that pseudo-metric is a generalization of a metric space in which the distance between two distinct points can be zero.\n",
    "We are given a set of $N$ pairs of points in $\\mathbf{R}^n$, $x_1, \\ldots, x_N$, and $y_1, \\ldots, y_N$, together with a set of distances $d_1, \\ldots, d_N > 0$.\n",
    "  The goal is to find (or estimate or learn) a quadratic pseudo-metric $d$\n",
    "  $$d(x,y) =  \\left( (x-y)^T P(x-y) \\right)^{1/2},$$\n",
    "  $P\\in \\mathbf{S}^n_{+}$, which approximates the given distances, i.e., $d(x_i, y_i) \\approx d_i$. (The pseudo-metric $d$ is a metric only when $P \\succ 0$; when $P\\succeq 0$ is singular, it is a pseudo-metric.)\n",
    "  \n",
    "  To do this, we will choose $P\\in \\mathbf{S}^n_+$ that minimizes the mean squared error objective\n",
    "  \n",
    "  $$f(S)=\\frac{1}{N}\\sum_{i=1}^N (d_i - d(x_i,y_i))^2.$$\n",
    "  \n",
    "  ### Theoretical part.\n",
    "  1. Show that the objective function $f$ is convex (Hint: expand the square and see what happens.)\n",
    "  2. Show that the convex program $\\text{minimize }f(S)$, $S\\succeq 0$ can be expressed by an equivalent conic program with linear objective and a number of conic constraints using the $R^n_+$ (nonnegative orthant cone), $Q^n$ (second order cone), $Q_r^n$ (rotated second order cone), $S^n_+$ (positive semidefinite cone).\n",
    "  \n",
    "  ### Programming Part\n",
    "  1. Solve the program $\\text{minimize }f(S)$, $S\\succeq 0$, preferably using a modelling package like ``cvxpy``. Note that \"under the hood\" your modelling package translates the program to the conic form in point 2. above.\n",
    "  2. Use the obtained $P$ to measure the mean square error for the test data ``X_test``, ``Y_test``, ``d_test``.\n",
    "  \n",
    "---- \n",
    "*This exercise originates from \"Additional Exercises\" collection for Convex Optimization textbook of S. Boyd and L. Vandenberghe. Used under permission*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8da0bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:29:47.889322Z",
     "start_time": "2024-05-14T13:29:46.997205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from scipy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d2b41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:30:11.293486Z",
     "start_time": "2024-05-14T13:30:11.264834Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this box we generate the input data\n",
    "\n",
    "np.random.seed(5680)\n",
    "\n",
    "n = 5 # Dimension\n",
    "N = 100 # Number of samples\n",
    "\n",
    "P = np.random.randn(n,n)\n",
    "P = P.dot(P.T) + np.identity(n)\n",
    "sqrtP = la.sqrtm(P)\n",
    "\n",
    "x = np.random.randn(N,n)\n",
    "y = np.random.randn(N,n)\n",
    "\n",
    "d = np.linalg.norm(sqrtP.dot((x-y).T),axis=0)    # distances according to metric P\n",
    "d = np.maximum(d+np.random.randn(N),0)           # add random noise\n",
    "\n",
    "N_test = 10 # Samples for test set\n",
    "X_test = np.random.randn(N_test,n)\n",
    "Y_test = np.random.randn(N_test,n)\n",
    "d_test = np.linalg.norm(sqrtP.dot((X_test-Y_test).T),axis=0)  # distances according to metric P\n",
    "d_test = np.maximum(d_test+np.random.randn(N_test),0)         # add random noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468d0df789708ce",
   "metadata": {},
   "source": [
    "## Theorethical part\n",
    "\n",
    "1.  From the lecture, we know that the domain of our function is convex. To prove that $f(S)$ is convex, it is enough to show that for each $i\\in\\{1,\\ldots,N\\}$, the component $(d_i - d(x_i,y_i))^2$ is convex (we can clearly ignore the constant $\\frac{1}{N}$ as $N > 0$). Furthermore, $(d_i - d(x_i,y_i))^2 = d_i^2 + (x_i-y_i)^T P (x_i-y_i) - 2d_i \\sqrt{ (x_i-y_i)^T P (x_i-y_i)}$.\n",
    "\n",
    "    Thus, we need to prove the function $$g_i(S) = d_i^2 + (x_i-y_i)^T S (x_i-y_i) - 2d_i \\sqrt{ (x_i-y_i)^T S (x_i-y_i)}$$ is convex.\n",
    "\n",
    "    Component $d_i^2$, as a constant, is convex. $(x_i-y_i)^T S (x_i-y_i)$ is a linear function with respect to the variable S, so it is convex. Moreover, from the lecture, $- 2d_i \\sqrt{ (x_i-y_i)^T S (x_i-y_i)}$ is convex as a composition of the convex non-increasing function $\\left(h(x) = -x\\right)$ with the concave function $\\left(g(x) = \\sqrt{x}\\right)$. Thus, $g_i$ is convex.\n",
    "\n",
    "    Therefore, the function $f$ is convex as a sum of convex functions.\n",
    "\n",
    "2.  We can add new two variable $a,b \\in\\mathbb{R}^N$ and rewrite our program to minimize $\\sum_{i=1}^{N} a_i - b_i$, where $(x_i-y_i)S   (x_i-y_i) \\leq a_i$ and $-2d_i\\sqrt{(x_i-y_i)S(x_i-y_i)} \\leq -b_i \\implies $   $ 4d_i^2 (x_i-y_i)S(x_i-y_i) \\geq  b_i^2$ for $\\newline i \\in \\{1,\\ldots, N\\}$. Therefore, our conic program will be:\n",
    "\n",
    "    $$\n",
    "    \\text{minimize} \\quad \\sum_{i=1}^{N} a_i - b_i\n",
    "    $$\n",
    "\n",
    "    subject to\n",
    "\n",
    "    $$\n",
    "    (b_i, 4d_i^2(x_i-y_i)^T S (x_i-y_i),1) \\succeq_{Q_r} 0, \\hspace{3mm}\\text{ where }  Q_r = \\{(x,t,s)\\in\\mathbb{R^{3}} :\\hspace{1mm} \\| x \\|^2_2\\leq ts\\} \\text{ for } i\\in \\{1,\\ldots,N\\} \\\\\n",
    "    a_i - (x_i-y_i)^T S (x_i-y_i) \\succeq_{R_+} 0, \\hspace{3mm} \\text{ for } i\\in \\{1,\\ldots,N\\} \\\\\n",
    "    S \\succeq_{S^n_{+} 0}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73481e76b1d08c49",
   "metadata": {},
   "source": [
    "## Programming part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f614bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.4.2                                    \n",
      "===============================================================================\n",
      "(CVXPY) May 22 11:33:10 PM: Your problem has 25 variables, 0 constraints, and 0 parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) May 22 11:33:10 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) May 22 11:33:10 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) May 22 11:33:10 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) May 22 11:33:10 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 22 11:33:10 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) May 22 11:33:10 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) May 22 11:33:10 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) May 22 11:33:10 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) May 22 11:33:10 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) May 22 11:33:10 PM: Applying reduction SCS\n",
      "(CVXPY) May 22 11:33:11 PM: Finished problem compilation (took 3.500e-01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 22 11:33:11 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.4 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 115, constraints m: 315\n",
      "cones: \t  q: soc vars: 300, qsize: 100\n",
      "\t  s: psd vars: 15, ssize: 1\n",
      "settings: eps_abs: 1.0e-05, eps_rel: 1.0e-05, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 100000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct-amd-qdldl\n",
      "\t  nnz(A): 3115, nnz(P): 0\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 4.52e+03  1.95e+03  1.57e+06 -7.85e+05  1.00e-01  4.77e-03 \n",
      "   250| 3.39e-01  5.08e+01  1.65e+02 -5.87e+03  9.03e+00  9.48e-03 \n",
      "   500| 4.90e-01  1.60e+00  1.50e+00 -7.08e+03  1.31e+00  1.41e-02 \n",
      "   750| 1.30e-01  3.00e-01  3.84e-01 -7.08e+03  1.31e+00  1.84e-02 \n",
      "  1000| 2.65e-02  1.62e-01  9.14e-02 -7.08e+03  1.31e+00  2.38e-02 \n",
      "  1250| 8.78e-03  1.32e-02  4.83e-03 -7.08e+03  1.31e+00  2.94e-02 \n",
      "  1500| 1.36e-03  7.42e-03  3.26e-04 -7.08e+03  1.31e+00  3.47e-02 \n",
      "  1575| 6.60e-04  1.37e-03  9.54e-04 -7.08e+03  1.31e+00  3.63e-02 \n",
      "------------------------------------------------------------------\n",
      "status:  solved\n",
      "timings: total: 3.64e-02s = setup: 3.16e-03s + solve: 3.32e-02s\n",
      "\t lin-sys: 1.56e-02s, cones: 1.32e-02s, accel: 6.82e-04s\n",
      "------------------------------------------------------------------\n",
      "objective = -7077.605782\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 22 11:33:11 PM: Problem status: optimal\n",
      "(CVXPY) May 22 11:33:11 PM: Optimal value: -7.078e+03\n",
      "(CVXPY) May 22 11:33:11 PM: Compilation took 3.500e-01 seconds\n",
      "(CVXPY) May 22 11:33:11 PM: Solver (including time spent in interface) took 3.692e-02 seconds\n",
      "Min f(S) 0.7203221132497128\n"
     ]
    }
   ],
   "source": [
    "S = cp.Variable((n,n), name='S', PSD=True)\n",
    "\n",
    "z = x - y\n",
    "\n",
    "obj = cp.Minimize(cp.sum([z[i].T @ S @ z[i] - 2 * d[i] * cp.sqrt(z[i].T @ S @ z[i]) for i in range(N)]))\n",
    "\n",
    "prob = cp.Problem(obj)\n",
    "\n",
    "prob.solve(verbose=True,solver=cp.SCS)\n",
    "print(f\"Min f(S) {(prob.value + np.sum([d[i]**2 for i in range(N)])) / N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b5b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared distance error : 0.9159307075239894\n"
     ]
    }
   ],
   "source": [
    "# Measure the mean square error for the test data X_test, Y_test, d_test.\n",
    "\n",
    "z_test = X_test - Y_test\n",
    "\n",
    "mse = (np.sum([(d_test[i] - np.sqrt(z_test[i].T @ S.value @ z_test[i]))**2 for i in range(N_test)])) / N_test\n",
    "print(f\"Mean squared distance error : {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
